{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyu34oT4n+4KCiuwGQe/zH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carmenpelayo/Carmen-Pelayo/blob/main/Spherical_KMeans_with_Cosine_Distance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \"Spherical KMeans  with Cosine Distance\"\n",
        "> Implementing kmeans with cosine distance"
      ],
      "metadata": {
        "id": "svsX_6oFRTkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "P-xY9AMfRbQ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH7LlduCRONR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algorithm\n",
        "The following shows my kmeans implementation. The steps are as follows:\n",
        "1. Choose `K_clusters` points from our dataset randomly and set them as our initial centroids.\n",
        "2. Iterate through all datapoints and assign each point to one of the centroids.\n",
        "3. Recalculate centroids based by averaging datapoints assigned to each cluster. As an additional step to usual kmeans, normalize to unit length.\n",
        "4. Repeat from step 2, for `epochs` iterations."
      ],
      "metadata": {
        "id": "cchKVaKNRgR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SKMeans:\n",
        "\n",
        "    def __init__(self, K_clusters, epochs = 10, alpha = 0.05):\n",
        "        self.K_clusters = K_clusters\n",
        "        self.epochs = epochs\n",
        "        self.W = None\n",
        "        self.index = None\n",
        "        self.similarities = []  \n",
        "        self.std = []  \n",
        "        self.nx = None\n",
        "        self.alpha = alpha\n",
        "\n",
        "\n",
        "    def fit(self, X, epochs = None):\n",
        "\n",
        "        # Initialization\n",
        "        d = X.size(dim=1)\n",
        "        n = X.size(dim=0)\n",
        "        if not self.W:\n",
        "            idx = np.random.choice(len(X), self.K_clusters, replace=False)\n",
        "            W = X[idx]\n",
        "            W = F.normalize(W)\n",
        "            nx = (1/self.K_clusters)*torch.ones(self.K_clusters)\n",
        "        else:\n",
        "            W = self.W\n",
        "            nx = self.nx\n",
        "        if not epochs:\n",
        "            epochs = self.epochs       \n",
        "\n",
        "        # Train   \n",
        "        for ep in tqdm(range(epochs)):\n",
        "            Z = X @ W.T\n",
        "            Zx, Ix = Z.max(dim=-1)\n",
        "            S = 1.*torch.eq(Zx,Z.T)\n",
        "            W = S @ X\n",
        "            W = F.normalize(W)\n",
        "            St = Zx.sum()/n # Similarity @ t\n",
        "            #std_n = torch.std(S.sum(dim=1)/n)\n",
        "            self.similarities.append(St.item())\n",
        "            #self.std.append(std_n.T.item())            \n",
        "            #print('Similarity:', St.item())       \n",
        "        self.index = Ix\n",
        "        self.W = W\n",
        "        self.nx = S.sum(dim=1)/n     "
      ],
      "metadata": {
        "id": "980yf8UzRhMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regions"
      ],
      "metadata": {
        "id": "97dctFwGRmtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section database `regions.xlsx` will be employed to create 8 clusters of regions in Europe. This database analyzes 270 NUTS-2 Regions in 21 socio-economic parameters. "
      ],
      "metadata": {
        "id": "x4SsQDXMTzKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "reg_vect = pd.read_excel('regions.xlsx', sheet_name = 'vectors')\n",
        "reg_info = pd.read_excel('regions.xlsx', sheet_name = 'info')"
      ],
      "metadata": {
        "id": "nn7kykEmRnp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = reg_vect.to_numpy()[:,1:]\n",
        "X = X.astype(np.float64)\n",
        "Xn = torch.from_numpy(X)\n",
        "Xn = Xn-torch.mean(Xn,0)\n",
        "Xn = Xn/torch.std(Xn,0)\n",
        "Xn = Xn.type(torch.FloatTensor)\n",
        "\n",
        "skmeans = SKMeans(8)\n",
        "skmeans.fit(Xn)\n",
        "plt.figure(1)\n",
        "plt.plot(skmeans.similarities)"
      ],
      "metadata": {
        "id": "9X88gZfuRs7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_vect['index'] = skmeans.index\n",
        "reg_index = reg_vect[['NUTS 2 Code','index']]\n",
        "reg_index.sort_values(by=['index'], inplace=True)\n",
        "reg_index = reg_index.merge(reg_info, how='left', left_on='NUTS 2 Code', right_on='Region')\n",
        "reg_index = reg_index[['index', 'Region', 'Region Name', 'geometry', 'Country Name']]\n",
        "reg_index['Region'].replace('', np.nan, inplace=True)\n",
        "reg_index.dropna(subset=['Region'], inplace=True)\n",
        "# Rename single columns\n",
        "reg_index = reg_index.rename(columns={'index' : 'Cluster', 'Region': 'NUTS_ID', 'geometry': 'center'})\n",
        "reg_index.to_excel(\"reg_index.xlsx\", index=False)\n",
        "print(reg_index)"
      ],
      "metadata": {
        "id": "YjxYlcg4RwyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install geemap\n",
        "!pip install geopandas"
      ],
      "metadata": {
        "id": "KZI9ck53R1jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "Y-PN2JXCR5Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nuts=gpd.read_file('NUTS_RG_20M_2021_4326-2.json')\n",
        "nuts2 = nuts[nuts.LEVL_CODE == 2]\n",
        "df_vects = pd.read_excel('reg_index.xlsx')\n",
        "df = pd.merge(nuts2, df_vects, how='inner', on='NUTS_ID')\n",
        "df.plot('Cluster', cmap=\"rainbow\",    figsize=(15, 10)) "
      ],
      "metadata": {
        "id": "evh9syolR8dy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}